{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade langchain openai  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # Install package\n",
    "%pip install --upgrade --quiet  \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = 'data'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=500,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "north are the plains of the five tributary rivers of the Punjab (Persian: Panjāb, “Five\n",
      "\n",
      "Waters”); in the centre the consolidated waters of the Indus and its tributaries flow through\n",
      "\n",
      "the alluvial plains of Sind; and in the south the waters pass naturally into the Indus delta.\n",
      "\n",
      "East of the latter is the Great Indian, or Thar, Desert, which is in turn bounded on the east\n",
      "\n",
      "by a hill system known as the Aravali Range, the northernmost extent of the Deccan plateau\n"
     ]
    }
   ],
   "source": [
    "print(docs[8].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires for open ai embedding\n",
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting openai\n",
      "  Downloading openai-1.7.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.7.1-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/224.9 kB 1.4 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 30.7/224.9 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/224.9 kB 655.4 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/224.9 kB 655.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 224.9/224.9 kB 917.3 kB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.7.0\n",
      "    Uninstalling openai-1.7.0:\n",
      "      Successfully uninstalled openai-1.7.0\n",
      "Successfully installed openai-1.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m      4\u001b[0m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      5\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe food was delicious and the waiter...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m   encoding_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=\"The food was delicious and the waiter...\",\n",
    "  encoding_format=\"float\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m pinecone\u001b[38;5;241m.\u001b[39minit(\n\u001b[0;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m38791c56-78f7-4b1c-915f-b7c255e75e3d\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# find at app.pinecone.io\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcp-starter\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# next to api key in console\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain-chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m index \u001b[38;5;241m=\u001b[39m Pinecone\u001b[38;5;241m.\u001b[39mfrom_documents(\u001b[43mdocs\u001b[49m, embeddings, index_name\u001b[38;5;241m=\u001b[39mindex_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "import pinecone \n",
    "from langchain.vectorstores import Pinecone\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=\"38791c56-78f7-4b1c-915f-b7c255e75e3d\",  # find at app.pinecone.io\n",
    "    environment=\"gcp-starter\"  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"langchain-chatbot\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m similar_docs\n\u001b[0;32m      8\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow is India economy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m similar_docs \u001b[38;5;241m=\u001b[39m \u001b[43mget_similiar_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m similar_docs\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m, in \u001b[0;36mget_similiar_docs\u001b[1;34m(query, k, score)\u001b[0m\n\u001b[0;32m      3\u001b[0m   similar_docs \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(query,k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m   similar_docs \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query,k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similar_docs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "def get_similiar_docs(query,k=1,score=False):\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query,k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query,k=k)\n",
    "  return similar_docs\n",
    "\n",
    "query = \"How is India economy\"\n",
    "similar_docs = get_similiar_docs(query)\n",
    "similar_docs\n",
    "\n",
    "\n",
    "import openai\n",
    "\n",
    "# Your existing code for loading, splitting documents, and setting up Pinecone goes here...\n",
    "\n",
    "def retrieve_context(query, k=5):\n",
    "    similar_docs = get_similiar_docs(query, k=k, score=False)\n",
    "    context = \" \".join([doc.page_content for doc in similar_docs])\n",
    "    return context\n",
    "\n",
    "def generate_response_with_context(query):\n",
    "    context = retrieve_context(query)\n",
    "    augmented_query = f\"Context: {context}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Use OpenAI's GPT model for text generation\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",  # Replace with your model of choice\n",
    "        prompt=augmented_query,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the health benefits of green tea?\"\n",
    "response = generate_response_with_context(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "model_name = \"gpt-3.5\"\n",
    "llm = OpenAI(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.1.9)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.0.79)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_similiar_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     23\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the health benefits of green tea?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m, in \u001b[0;36mgenerate_response_with_context\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response_with_context\u001b[39m(query):\n\u001b[1;32m---> 11\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     augmented_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Use OpenAI's GPT model for text generation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mretrieve_context\u001b[1;34m(query, k)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_context\u001b[39m(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     similar_docs \u001b[38;5;241m=\u001b[39m \u001b[43mget_similiar_docs\u001b[49m(query, k\u001b[38;5;241m=\u001b[39mk, score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m similar_docs])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_similiar_docs' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Your existing code for loading, splitting documents, and setting up Pinecone goes here...\n",
    "\n",
    "def retrieve_context(query, k=5):\n",
    "    similar_docs = get_similiar_docs(query, k=k, score=False)\n",
    "    context = \" \".join([doc.page_content for doc in similar_docs])\n",
    "    return context\n",
    "\n",
    "def generate_response_with_context(query):\n",
    "    context = retrieve_context(query)\n",
    "    augmented_query = f\"Context: {context}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Use OpenAI's GPT model for text generation\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",  # Replace with your model of choice\n",
    "        prompt=augmented_query,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the health benefits of green tea?\"\n",
    "response = generate_response_with_context(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
